# -*- coding: utf-8 -*-
"""Submission Klasifikasi Genre Film - Diggy Bani Nusantara.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eYvczYAdS3nT8U27P2JQiPiPt7RAZ6Yc

Nama : Diggy Bani Nusantara; Kelas : Belajar Machine Learning Untuk Pemula; No. Registrasi : 1494037162101-336; Program : FGA; Klasifikasi Genre Film;
"""

#Library
from google.colab import files 
import pandas as pd
import re

from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

import matplotlib.pyplot as plt

!pip install -q Kaggle

uploaded = files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d lokkagle/movie-genre-data
!unzip movie-genre-data.zip -d train

#Link Dataset https://www.kaggle.com/lokkagle/movie-genre-data
df = pd.read_csv("/content/train/kaggle_movie_train.csv")
df.head()

#Jumlah Dataset Genre
df['genre'].value_counts()

df = df[~df['genre'].isin(['drama','thriller','other','adventure','romance'])]
df['genre'].value_counts()

#Preprocessing
df['Text'] = df['text'].map(lambda x: re.sub(r'\W+', ' ', x))

df = df.drop(['id', 'text'], axis=1)
df.head()

#Label Genre Categorical
genre = pd.get_dummies(df.genre)
df_genre = pd.concat([df, genre], axis=1)
df_genre = df_genre.drop(columns='genre')
df_genre.head()

text = df_genre['Text'].astype(str)
label = df_genre[['comedy', 'action','sci-fi','horror']].values

#Split Validation 20%
genre_train, genre_test, label_train, label_test = train_test_split(text, label, test_size = 0.2)

#Tokenisasi
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(genre_train) 
tokenizer.fit_on_texts(genre_test)
 
sequens_train = tokenizer.texts_to_sequences(genre_train)
sequens_test = tokenizer.texts_to_sequences(genre_test)
 
padded_train = pad_sequences(sequens_train) 
padded_test = pad_sequences(sequens_test)

#Sequential, LSTM, Embedding
model = Sequential([
        Embedding(input_dim=5000, output_dim=16),
        LSTM(64),
        Dense(64, activation='relu'),
        Dropout(0.5),
        Dense(4, activation='softmax')
])

#Compile
Adam(learning_rate=0.000128, name='adam')
model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])

#Callback
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.9):
      print("\nAkurasi Sudah Lebih 90%!")
      self.model.stop_training = True
callbacks = myCallback()

num_epochs = 30
history = model.fit(
    padded_train,
    label_train,
    epochs=num_epochs,
    validation_data=(padded_test, label_test),
    verbose=2,
    callbacks=[callbacks])

#Plot Accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Plot Accuration')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

#Plot Loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Plot Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()